"""
íì•” ë°ì´í„° ì „ì²˜ë¦¬ ë° íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import os

def load_and_explore_data(csv_path):
    """ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ íƒìƒ‰"""
    
    print("="*70)
    print("1. ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´")
    print("="*70)
    
    df = pd.read_csv(csv_path)
    
    print(f"\nğŸ“Š ë°ì´í„° í¬ê¸°: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")
    print(f"\nğŸ“‹ ì»¬ëŸ¼ ëª©ë¡:")
    print(df.columns.tolist())
    
    print(f"\nğŸ” ë°ì´í„° íƒ€ì…:")
    print(df.dtypes)
    
    print(f"\nğŸ“ˆ ê¸°ë³¸ í†µê³„:")
    print(df.describe())
    
    print(f"\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬:")
    print(df['LUNG_CANCER'].value_counts())
    print(f"ë¹„ìœ¨: {df['LUNG_CANCER'].value_counts(normalize=True) * 100}")
    
    return df

def check_data_quality(df):
    """ë°ì´í„° í’ˆì§ˆ í™•ì¸ (ê²°ì¸¡ì¹˜, ì¤‘ë³µ, ì´ìƒì¹˜)"""
    
    print("\n" + "="*70)
    print("2. ë°ì´í„° í’ˆì§ˆ í™•ì¸")
    print("="*70)
    
    # ê²°ì¸¡ì¹˜ í™•ì¸
    print("\nâ“ ê²°ì¸¡ì¹˜ í™•ì¸:")
    missing = df.isnull().sum()
    if missing.sum() == 0:
        print("âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ!")
    else:
        print(missing[missing > 0])
        print(f"ì´ ê²°ì¸¡ì¹˜: {missing.sum()}ê°œ")
    
    # ì¤‘ë³µ í–‰ í™•ì¸
    duplicates = df.duplicated().sum()
    print(f"\nğŸ”„ ì¤‘ë³µ í–‰: {duplicates}ê°œ")
    if duplicates > 0:
        print("âš ï¸  ì¤‘ë³µ í–‰ ì œê±° ê¶Œì¥")
    else:
        print("âœ… ì¤‘ë³µ í–‰ ì—†ìŒ!")
    
    # ê° ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ í™•ì¸
    print("\nğŸ”¢ ê° ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ ê°œìˆ˜:")
    for col in df.columns:
        unique_count = df[col].nunique()
        unique_values = df[col].unique()
        print(f"  {col}: {unique_count}ê°œ â†’ {unique_values[:5]}")
    
    return df

def preprocess_data(df):
    """ë°ì´í„° ì „ì²˜ë¦¬"""
    
    print("\n" + "="*70)
    print("3. ë°ì´í„° ì „ì²˜ë¦¬")
    print("="*70)
    
    df_processed = df.copy()
    
    # 1. ì¤‘ë³µ ì œê±°
    original_size = len(df_processed)
    df_processed = df_processed.drop_duplicates()
    removed_duplicates = original_size - len(df_processed)
    print(f"\nğŸ—‘ï¸  ì¤‘ë³µ í–‰ ì œê±°: {removed_duplicates}ê°œ")
    
    # 2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìˆë‹¤ë©´)
    if df_processed.isnull().sum().sum() > 0:
        print("\nğŸ”§ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì¤‘...")
        # ìˆ˜ì¹˜í˜•: ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´
        numeric_cols = df_processed.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if df_processed[col].isnull().sum() > 0:
                median_val = df_processed[col].median()
                df_processed[col].fillna(median_val, inplace=True)
                print(f"  {col}: ì¤‘ì•™ê°’({median_val})ìœ¼ë¡œ ëŒ€ì²´")
        
        # ë²”ì£¼í˜•: ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´
        categorical_cols = df_processed.select_dtypes(include=['object']).columns
        for col in categorical_cols:
            if df_processed[col].isnull().sum() > 0:
                mode_val = df_processed[col].mode()[0]
                df_processed[col].fillna(mode_val, inplace=True)
                print(f"  {col}: ìµœë¹ˆê°’({mode_val})ìœ¼ë¡œ ëŒ€ì²´")
    else:
        print("\nâœ… ê²°ì¸¡ì¹˜ ì—†ìŒ - ì²˜ë¦¬ ë¶ˆí•„ìš”")
    
    # 3. ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
    print("\nğŸ”¤ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©:")
    
    # ì„±ë³„ ì¸ì½”ë”© (M=1, F=0)
    if 'GENDER' in df_processed.columns:
        df_processed['GENDER'] = df_processed['GENDER'].map({'M': 1, 'F': 0})
        print("  âœ“ GENDER: Mâ†’1, Fâ†’0")
    
    # íƒ€ê²Ÿ ë³€ìˆ˜ ì¸ì½”ë”© (YES=1, NO=0)
    if 'LUNG_CANCER' in df_processed.columns:
        df_processed['LUNG_CANCER'] = df_processed['LUNG_CANCER'].map({'YES': 1, 'NO': 0})
        print("  âœ“ LUNG_CANCER: YESâ†’1, NOâ†’0")
    
    # 4. ë°ì´í„° íƒ€ì… í™•ì¸
    print("\nğŸ“ ì „ì²˜ë¦¬ í›„ ë°ì´í„° íƒ€ì…:")
    print(df_processed.dtypes.value_counts())
    
    print(f"\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ìµœì¢… ë°ì´í„° í¬ê¸°: {df_processed.shape}")
    
    return df_processed

def analyze_features(df):
    """íŠ¹ì„± ë¶„ì„"""
    
    print("\n" + "="*70)
    print("4. íŠ¹ì„± ë¶„ì„")
    print("="*70)
    
    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„
    print("\nğŸ“Š ì£¼ìš” íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„:")
    if 'LUNG_CANCER' in df.columns:
        correlations = df.corr()['LUNG_CANCER'].sort_values(ascending=False)
        print(correlations)
        
        print("\nğŸ” íƒ€ê²Ÿê³¼ ê°€ì¥ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ íŠ¹ì„± (ìƒìœ„ 5ê°œ):")
        top_features = correlations.drop('LUNG_CANCER').head(5)
        for feature, corr in top_features.items():
            print(f"  {feature}: {corr:.4f}")
    
    # í´ë˜ìŠ¤ ë¶ˆê· í˜• í™•ì¸
    print("\nâš–ï¸  í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„:")
    if 'LUNG_CANCER' in df.columns:
        class_distribution = df['LUNG_CANCER'].value_counts()
        total = len(df)
        print(f"  í´ë˜ìŠ¤ 0 (ìŒì„±): {class_distribution.get(0, 0)}ê°œ ({class_distribution.get(0, 0)/total*100:.1f}%)")
        print(f"  í´ë˜ìŠ¤ 1 (ì–‘ì„±): {class_distribution.get(1, 0)}ê°œ ({class_distribution.get(1, 0)/total*100:.1f}%)")
        
        imbalance_ratio = max(class_distribution) / min(class_distribution)
        print(f"  ë¶ˆê· í˜• ë¹„ìœ¨: {imbalance_ratio:.2f}:1")
        
        if imbalance_ratio > 2:
            print("  âš ï¸  í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡´ì¬ â†’ class_weight='balanced' ê¶Œì¥")
        else:
            print("  âœ… í´ë˜ìŠ¤ ê· í˜• ì–‘í˜¸")

def split_and_scale_data(df, test_size=0.2, random_state=42):
    """ë°ì´í„° ë¶„ë¦¬ ë° ìŠ¤ì¼€ì¼ë§"""
    
    print("\n" + "="*70)
    print("5. ë°ì´í„° ë¶„ë¦¬ ë° ìŠ¤ì¼€ì¼ë§")
    print("="*70)
    
    # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
    X = df.drop('LUNG_CANCER', axis=1)
    y = df['LUNG_CANCER']
    
    print(f"\nğŸ“¦ íŠ¹ì„±(X) í¬ê¸°: {X.shape}")
    print(f"ğŸ¯ íƒ€ê²Ÿ(y) í¬ê¸°: {y.shape}")
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=test_size, 
        random_state=random_state,
        stratify=y  # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
    )
    
    print(f"\nâœ‚ï¸  ë°ì´í„° ë¶„ë¦¬ ì™„ë£Œ:")
    print(f"  í•™ìŠµ ì„¸íŠ¸: {X_train.shape[0]}ê°œ ({(1-test_size)*100:.0f}%)")
    print(f"  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {X_test.shape[0]}ê°œ ({test_size*100:.0f}%)")
    
    # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
    print(f"\ní•™ìŠµ ì„¸íŠ¸ í´ë˜ìŠ¤ ë¶„í¬:")
    print(f"  ìŒì„±: {(y_train==0).sum()}ê°œ")
    print(f"  ì–‘ì„±: {(y_train==1).sum()}ê°œ")
    
    print(f"\ní…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í´ë˜ìŠ¤ ë¶„í¬:")
    print(f"  ìŒì„±: {(y_test==0).sum()}ê°œ")
    print(f"  ì–‘ì„±: {(y_test==1).sum()}ê°œ")
    
    # ìŠ¤ì¼€ì¼ë§ (ì„ íƒì  - íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì—ëŠ” ë¶ˆí•„ìš”í•˜ì§€ë§Œ ì°¸ê³ ìš©)
    print("\nğŸ“ ìŠ¤ì¼€ì¼ë§ (ì°¸ê³ ìš© - Random ForestëŠ” ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”):")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    print("  âœ“ StandardScaler ì ìš© ì™„ë£Œ")
    print(f"  í‰ê· : {X_train_scaled.mean():.6f}")
    print(f"  í‘œì¤€í¸ì°¨: {X_train_scaled.std():.6f}")
    
    return X_train, X_test, y_train, y_test, X.columns.tolist()

def main():
    """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    
    # ë°ì´í„° ê²½ë¡œ
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(current_dir)
    csv_path = os.path.join(project_dir, 'survey lung cancer.csv')
    
    print("\n" + "ğŸ« "*20)
    print("íì•” ë°ì´í„° ì „ì²˜ë¦¬ ë° íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)")
    print("ğŸ« "*20)
    
    # 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰
    df = load_and_explore_data(csv_path)
    
    # 2. ë°ì´í„° í’ˆì§ˆ í™•ì¸
    df = check_data_quality(df)
    
    # 3. ë°ì´í„° ì „ì²˜ë¦¬
    df_processed = preprocess_data(df)
    
    # 4. íŠ¹ì„± ë¶„ì„
    analyze_features(df_processed)
    
    # 5. ë°ì´í„° ë¶„ë¦¬ ë° ìŠ¤ì¼€ì¼ë§
    X_train, X_test, y_train, y_test, feature_names = split_and_scale_data(df_processed)
    
    print("\n" + "="*70)
    print("âœ… ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("="*70)
    print("\nì´ì œ train_model.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("ëª…ë ¹ì–´: python lungcancer/train_model.py")
    
    return df_processed, X_train, X_test, y_train, y_test, feature_names

if __name__ == '__main__':
    main()

